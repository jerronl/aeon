{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fXJ4VA6GZoK"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaXYxzifbhst",
        "outputId": "ad623fbe-0c9b-4ed6-a6a7-7c0f1425616c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting git+https://github.com/jerronl/rtdl.git\n",
            "  Cloning https://github.com/jerronl/rtdl.git to /tmp/pip-req-build-b4yuklpv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jerronl/rtdl.git /tmp/pip-req-build-b4yuklpv\n",
            "  Resolved https://github.com/jerronl/rtdl.git to commit f98ce61e5574c18e249a21e417e208f4832de808\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.10/dist-packages (from rtdl==0.0.14.dev0) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from rtdl==0.0.14.dev0) (1.2.2)\n",
            "Requirement already satisfied: torch<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from rtdl==0.0.14.dev0) (2.1.0+cu118)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from rtdl==0.0.14.dev0) (4.5.0)\n",
            "Collecting pynvml<9,>=8.0 (from rtdl==0.0.14.dev0)\n",
            "  Downloading pynvml-8.0.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from rtdl==0.0.14.dev0) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1.0->rtdl==0.0.14.dev0) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1.0->rtdl==0.0.14.dev0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1.0->rtdl==0.0.14.dev0) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7->rtdl==0.0.14.dev0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.7->rtdl==0.0.14.dev0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.7->rtdl==0.0.14.dev0) (1.3.0)\n",
            "Building wheels for collected packages: rtdl\n",
            "  Building wheel for rtdl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rtdl: filename=rtdl-0.0.14.dev0-py3-none-any.whl size=77961 sha256=91f8054f683105540602f71fbf6099c8714ff8390928627e3ebcf135b7b6fbf8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-otlxzppv/wheels/8d/92/7b/32aaeaca71d3de56c377bd2561972e24497e709ff9f9d967cc\n",
            "Successfully built rtdl\n",
            "Installing collected packages: pynvml, rtdl\n",
            "Successfully installed pynvml-8.0.4 rtdl-0.0.14.dev0\n",
            "GPU mem:16G, batch_size:128\n"
          ]
        }
      ],
      "source": [
        "tables = ['volcvg.csv']\n",
        "mydrive= 'E:/mydoc/git/trade/analyics/'\n",
        "# \"\"\"\n",
        "tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "mydrive='/content/drive/MyDrive/volrt/'\n",
        "# Requirements:\n",
        "import os\n",
        "if not os.path.exists('/usr/local/lib/python3.10/dist-packages/rtdl'):\n",
        "  %pip install git+https://github.com/jerronl/rtdl.git\n",
        "#\"\"\"\n",
        "\n",
        "appname='Xcj_'\n",
        "duration = 6\n",
        "bad_value=-99999\n",
        "vars_h, cat_names, ys,vars_c,= (\n",
        "    ['date', 'diff', 'spot'],\n",
        "    [],\n",
        "    [[\n",
        "        'close', 'hi', 'lo',\n",
        "        'dtm','level','slope','curve',\n",
        "         'dtm1','level1','slope1','curve1',\n",
        "         'dtm2','level2','slope2','curve2',\n",
        "         'dtm3','level3','slope3','curve3'],\n",
        "         [ 'pmcat',],],\n",
        "    ['Horizon','spot','time'],\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "vars_h+=ys[0]\n",
        "dep_vars=ys#[duration]\n",
        "# vars_c=vars_c[duration]\n",
        "\n",
        "ignore_load_zero=ignore_load_error=y_std=y_mean=X=y=loss_fn=my_model=jobsize=offset=start_epoch=optimizer=rand_seed = None\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from typing import Any, Dict\n",
        "import rtdl\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import rtdl.zero as zero\n",
        "import matplotlib.pyplot as plt,os\n",
        "%matplotlib inline\n",
        "from typing import Optional\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from pickle import dump, load\n",
        "import seaborn as sns\n",
        "import random\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import xlrd\n",
        "from itertools import product\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.13-cp38-cp38-linux_x86_64.whl --force-reinstall\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "zero.improve_reproducibility(seed=1234567)\n",
        "batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*8\n",
        "print(f'GPU mem:{int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)}G, batch_size:{batch_size}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yvhMlfybhsu"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO5rRKCxbhsv"
      },
      "outputs": [],
      "source": [
        "def cyclic_encode(data,feature,original,period,names):\n",
        "  data[f'sin_{feature}'] = np.sin(2 * np.pi * original/period)\n",
        "  data[f'cos_{feature}'] = np.cos(2 * np.pi * original/period)\n",
        "  names.extend([f'sin_{feature}',f'cos_{feature}'])\n",
        "\n",
        "def get_cont_names(next_run=None):\n",
        "  cont_names, dfo  = [f'{x[0]}_{x[1]+1}' for x in product(vars_h,range(duration))], pd.DataFrame()\n",
        "  for table in tables:\n",
        "      df = pd.read_csv(mydrive + table)\n",
        "      if next_run:\n",
        "        df=df.query(f'date>\"#{next_run}\"')\n",
        "      df['source']=table\n",
        "      dfo = pd.concat([dfo, df])\n",
        "  dfo.sort_values(by=['date'],inplace=True)\n",
        "  for cyclic in ['date_1','date_2','date_3','date_4','date_5','date_6']:\n",
        "    cyclics=np.vectorize(lambda x: x.timetuple())(pd.to_datetime(dfo[cyclic], unit='D', origin='1899-12-30').astype('object'))\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  for cyclic in ['diff_1','diff_2','diff_3','diff_4','diff_5','diff_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],70,cont_names)\n",
        "  for cyclic in ['dtm_1','dtm_2','dtm_3','dtm_4','dtm_5','dtm_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],5,cont_names)\n",
        "  cont_names.sort()\n",
        "  for cyclic in ['date']:\n",
        "    cyclics=np.vectorize(lambda x: datetime(int(x[1:5]),int(x[6:8]),int(x[9:11]),int(x[12:14]),int(x[15:17]),int(x[18:20]),).timetuple())(dfo[cyclic])\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  assert len(cont_names) % 6==0\n",
        "  dfo['time']=np.modf(dfo['date_6'])[0]\n",
        "  return dfo, cont_names\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, position=None):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        if position is None:\n",
        "            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
        "        # Used for tensors that need to be on the same device as the module.\n",
        "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "class PETrans(nn.Module):\n",
        "\n",
        "    def __init__(self, duration, d_model,n_num_features,cat_cardinalities,d_out,x2):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        print(\"PETrans\",duration, d_model,n_num_features,cat_cardinalities,d_out,x2)\n",
        "        super().__init__()\n",
        "        # Input dim -> Model dim\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Linear(duration, d_model*2), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Dropout(0.1), #self.hparams.input_dropout),\n",
        "            nn.GELU(), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Linear(d_model*2, d_model), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "        )\n",
        "        # Positional encoding for sequences\n",
        "        self.positional_encoding = PositionalEncoding(d_model=d_model)\n",
        "        self.unf=nn.Flatten(1,2)\n",
        "        self.ftt= rtdl.FTTransformer.make_default(\n",
        "            n_num_features=int(n_num_features/duration*d_model+x2),\n",
        "            cat_cardinalities=cat_cardinalities,\n",
        "            d_out=d_out,\n",
        "            )\n",
        "\n",
        "    def forward(self, x_num: Optional[Tensor], x_cat: Optional[Tensor], x2: Optional[Tensor]) -> Tensor:\n",
        "        x = self.input_net(x_num)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.unf(x)\n",
        "        x = torch.cat((x, x2), 1)\n",
        "        x = self.ftt(x, x_cat)\n",
        "        return x\n",
        "\n",
        "    def make_default_optimizer(self) -> torch.optim.AdamW:\n",
        "        \"\"\"Make the optimizer for the default FT-Transformer.\"\"\"\n",
        "        return self.ftt.make_default_optimizer()\n",
        "\n",
        "def apply_model(model, x_num, x_cat=None, x2=None):\n",
        "    return model(x_num, x_cat, x2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mload=None,part='val'):\n",
        "    model=mload or my_model\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], batch_size):\n",
        "        prediction.append(apply_model(model,\n",
        "                                      x_cat=batch[0] if len(cat_names)>0 else None,\n",
        "                                      x_num=batch[1],x2=batch[2]))\n",
        "    prediction = torch.cat(prediction)\n",
        "    target = y[part]\n",
        "    prediction2 = prediction[:,-y_cat:].argmax(1)\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    score = (F.mse_loss(prediction[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "          ((target[:,-1]!=prediction2).sum()/len(prediction))\n",
        "\n",
        "    return score,target, prediction,prediction2\n",
        "\n",
        "def plot_result(target, prediction, prediction2, compare=False):\n",
        "  sns.jointplot(x=target[:,-1] , y=prediction2,kind=\"kde\",fill=True,rug=True)\n",
        "  prediction[:,-y_cat]=prediction2\n",
        "  sns.set(style=\"whitegrid\")\n",
        "  print(f'mse={np.mean((target[:,-1] - prediction2)**2)}')\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  figs=min(len(dep_var),4)\n",
        "  _, axes = plt.subplots(math.ceil(len(dep_var)/figs), figs, figsize=(16,16))\n",
        "  for i,name in enumerate(dep_var):\n",
        "      axs=axes.flat[i] if figs>1 else axes\n",
        "      sns.regplot(ax=axs, x=target[:,i] , y=prediction[:,i],\n",
        "                scatter_kws = {'color': 'purple', 'alpha': 0.3},\n",
        "                line_kws = {'color': '#CCCC00', 'alpha': 0.3}\n",
        "                )\n",
        "      axs.set_title(name)\n",
        "      mask=~np.isnan(target[:,i])\n",
        "      if len(target[:,i][mask])>0:\n",
        "        if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "\n",
        "          axs.set_xlim(left=max(np.min(target[:,i][mask]), -2.5),\n",
        "                        right=min(np.max(target[:,i][mask]),2.5))\n",
        "        else:\n",
        "          axs.set_xlim(left=np.min(target[:,i][mask]),\n",
        "                              right=np.max(target[:,i][mask]))\n",
        "  plt.show()\n",
        "  if compare:\n",
        "    for i,name in enumerate(dep_var):\n",
        "      if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "        plt.plot(target[:,i],label=f'actual {name}')\n",
        "        plt.plot(prediction[:,i],label=f'forecast {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(mload=None, threshold=10):\n",
        "  score,target, prediction,prediction2 = evaluate(mload,'test')\n",
        "  print(jobname,f'{score:.4f}')\n",
        "  if score>threshold:\n",
        "    return\n",
        "  target, prediction, prediction2 = target.squeeze(1).cpu().numpy(), prediction.squeeze(1).cpu().numpy(), prediction2.cpu().numpy()\n",
        "  plot_result(target, prediction,prediction2)\n",
        "\n",
        "def cross_entropy_mse_loss_with_nans(input, target):\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    return (F.mse_loss(input[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "      (F.cross_entropy (input[:,-y_cat:],target[:,-1].type(torch.LongTensor).to(device)))\n",
        "\n",
        "def model_path():\n",
        "  return mydrive+jobname+'checkpoint.pt'\n",
        "\n",
        "def save_model(improved=False):\n",
        "  path=mydrive+jobname+'checkpoint.pt'\n",
        "  torch.save(\n",
        "      {\n",
        "          'model_':  my_model.state_dict() if improved or not os.path.exists(path) else\n",
        "                    torch.load(path)['model_'],\n",
        "          'model'       : my_model.state_dict(),\n",
        "          'optimizer'   : optimizer.state_dict(),\n",
        "          'epoch'       : epoch,\n",
        "          'random_state': zero.random.get_state (),\n",
        "          'jobsize'     : jobsize,\n",
        "          'offset'      : offset,\n",
        "          'rand_seed'    : rand_seed,\n",
        "      },\n",
        "      path\n",
        "  )\n",
        "\n",
        "def load_model(load_good=False,keep_seed=True):\n",
        "  global jobsize,offset,start_epoch,my_model,optimizer,rand_seed\n",
        "  start_epoch=1\n",
        "  jobsize=int(len(X_all)*0.1)\n",
        "  if resume:\n",
        "    path=mydrive+jobname+'checkpoint.pt'\n",
        "    if os.path.exists(path):\n",
        "      try:\n",
        "        checkpoint = torch.load(path,map_location=device)\n",
        "        my_model.load_state_dict(checkpoint['model_'if load_good else 'model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        if 'rand_seed' in checkpoint and keep_seed:\n",
        "          rand_seed=checkpoint['rand_seed']\n",
        "        try:\n",
        "          zero.random.set_state(checkpoint['random_state'])\n",
        "        except (AssertionError,) as err:\n",
        "          if ignore_load_zero:\n",
        "            print(\"zero error:\",err)\n",
        "          else:\n",
        "            raise err\n",
        "        print(f'loaded {jobname} epoch {start_epoch}')\n",
        "        if 'jobsize' in checkpoint and checkpoint['jobsize']<=jobsize:\n",
        "          offset=checkpoint['offset']\n",
        "          if checkpoint['jobsize']<jobsize:\n",
        "            print('Job size increased from ', checkpoint['jobsize'], ' to ', jobsize)\n",
        "            if offset<0:\n",
        "              offset+=checkpoint['jobsize']*10\n",
        "        else:\n",
        "          raise ValueError('size diffs now',jobsize,\n",
        "                checkpoint['jobsize'] if 'jobsize' in checkpoint else 0)\n",
        "        return True\n",
        "      except Exception as error:\n",
        "        if ignore_load_error:\n",
        "          print(\"failed to load: \", error)\n",
        "        else:\n",
        "          raise error\n",
        "  random.seed(datetime.now().timestamp())\n",
        "  offset=random.randint(-jobsize*3,-jobsize*2)+jobsize*10\n",
        "  return False\n",
        "\n",
        "def job_name():\n",
        "  return appname+''.join(filter(lambda x: x not in \"[' \", str(dep_vars[0])))[:8]\n",
        "\n",
        "def setup_data(mis=False):\n",
        "  global jobname,X,y, my_model,optimizer,train_loader,progress,y_mean,y_std,loss_fn,y_cat,rand_seed\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  jobname=job_name()\n",
        "  y_all=torch.tensor(dfo.loc[:,dep_var].to_numpy(), device=device)\n",
        "\n",
        "  y_cat = 22#int(max(y_all[:,-1]))\n",
        "  y_all[:,-1]-=1\n",
        "  d_out = y_cat+y_all.shape[1]-1\n",
        "\n",
        "  X,y = {},{}\n",
        "  my_model=PETrans(\n",
        "      duration=duration,\n",
        "      d_model=16,\n",
        "      n_num_features=len(cont_names),\n",
        "      cat_cardinalities=[len(arr) for arr in enc.categories_],\n",
        "      d_out=d_out,\n",
        "      x2=len(vars_c)\n",
        "      ).to(device)\n",
        "\n",
        "  optimizer = (\n",
        "      my_model.make_default_optimizer()\n",
        "  )\n",
        "  load_model(load_good=mis,keep_seed= not mis)\n",
        "\n",
        "  X['train'], X['test'], y['train'], y['test']  = (\n",
        "      np.concatenate((X_all[:offset],X_all[offset+jobsize:])),\n",
        "      X_all[offset:offset+jobsize],\n",
        "      torch.cat((y_all[:offset],y_all[offset+jobsize:])),\n",
        "      y_all[offset:offset+jobsize],\n",
        "  )\n",
        "  if rand_seed is None:\n",
        "    rand_seed=np.random.default_rng().integers(99999)\n",
        "  print(jobname,y_all.shape,'offset ',offset,dfo['date'].iloc[offset],'seed', rand_seed)\n",
        "  X['train'], X['val'],  y['train'], y['val']  = sklearn.model_selection.train_test_split(\n",
        "      X['train'], y['train'], train_size=0.95, random_state=rand_seed\n",
        "  )\n",
        "  X2, X['test'], y2, y['test']  = sklearn.model_selection.train_test_split(\n",
        "      X['test'], y['test'], train_size=0.05, random_state=rand_seed\n",
        "  )\n",
        "  X['val'], y['val']=np.concatenate((X['val'], X['test'])),torch.cat(( y['val'], y['test']))\n",
        "  X['train'], y['train']=np.concatenate((X['train'], X2)),torch.cat(( y['train'], y2))\n",
        "\n",
        "  X = {\n",
        "      k: (torch.tensor(v[:,:len(cat_names)], device=device).to(torch.int64),\n",
        "          torch.tensor(v[:,-len(cont_names):].reshape((v.shape[0],int(len(cont_names)/duration),duration)), device=device),\n",
        "          torch.tensor(v[:,len(cat_names):-len(cont_names)], device=device),)\n",
        "      for k, v in X.items()\n",
        "  }\n",
        "  # y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "  mask=torch.masked.masked_tensor(y['train'],y['train']!=bad_value)\n",
        "  y_mean,y_std=mask.mean(dim=0).to_tensor(0),mask.std(dim=0).to_tensor(0)\n",
        "  cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "  for k,v in y.items():\n",
        "    v[v==bad_value]=float('nan')\n",
        "    v[:,cols_to_norm]=((v-y_mean) / y_std)[:,cols_to_norm]\n",
        "    y[k]=v\n",
        "\n",
        "\n",
        "  y = {k: v.float() for k, v in y.items()}\n",
        "\n",
        "  train_loader = zero.data.IndexLoader(len(X['train'][0]), batch_size, device=device)\n",
        "  progress = zero.ProgressTracker(patience=100)\n",
        "  loss_fn = cross_entropy_mse_loss_with_nans\n",
        "\n",
        "def boxplot(vars,bad_value=None):\n",
        "  i=j=min(5,len(vars))\n",
        "  for _,var in enumerate(vars):\n",
        "      if isinstance(var,list):\n",
        "        y=pd.Series()\n",
        "        for name in var:\n",
        "          if name in dfo.columns:\n",
        "            y=y.append(dfo[name],ignore_index = True)\n",
        "      else:\n",
        "        y=dfo[var] if var in dfo.columns else []\n",
        "        name=var\n",
        "      if len(y)>0:\n",
        "        if i>=j:\n",
        "          figure, axes = plt.subplots(1,j,figsize=(16,8))\n",
        "          i=0\n",
        "        axs=axes.flat[i]\n",
        "        i+=1\n",
        "        if bad_value is not None and y.min()<=bad_value:\n",
        "          mask=y!=bad_value\n",
        "          name=f'{name}_{mask.sum()/len(mask):.0%}'\n",
        "          y=y[mask]\n",
        "        sns.boxplot(ax=axs, y=y, showmeans=True,\n",
        "                          meanprops={\"marker\": \"+\",\n",
        "                        \"markeredgecolor\": \"black\",\n",
        "                        \"markersize\": \"10\"})\n",
        "        axs.set_title(name)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def set_state(state: Dict[str, Any]) -> None:\n",
        "    \"\"\"Set global random states in `random`, `numpy` and `torch`.\n",
        "\n",
        "    Args:\n",
        "        state: global RNG states. Must be produced by `get_state`. The size of the list\n",
        "            :code:`state['torch.cuda']` must be equal to the number of available cuda\n",
        "            devices.\n",
        "\n",
        "    See also:\n",
        "        `get_state`\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: if :code:`torch.cuda.device_count() != len(state['torch.cuda'])`\n",
        "    \"\"\"\n",
        "    random.setstate(state['random'])\n",
        "    np.random.set_state(state['numpy.random'])\n",
        "    torch.random.set_rng_state(state['torch.random'].cpu())\n",
        "    assert torch.cuda.device_count() == len(state['torch.cuda'])\n",
        "    torch.cuda.set_rng_state_all([v.cpu() for v in state['torch.cuda']])  # type: ignore\n",
        "\n",
        "zero.random.set_state=set_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCgUZWimvIwD"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "my_model.cpu()\n",
        "del my_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d704z1qGZoM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rcixIV4GZoO"
      },
      "outputs": [],
      "source": [
        "# next_dep = 0\n",
        "# next_dep=1\n",
        "# next_dep=2\n",
        "# next_dep=3\n",
        "resume = True  # False#\n",
        "# tables = ['volcva.csv']\n",
        "# tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "dfo, cont_names=get_cont_names()\n",
        "\n",
        "# dfo.sort_values(by=['date'],inplace=True)\n",
        "enc = OrdinalEncoder()\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "\n",
        "print(dfo.shape, X_all.shape,len(dep_vars[0]))\n",
        "zero_perc=(1-len(dfo[dfo['close']>0])/len(dfo)+len(dfo[dfo['close']<0])/len(dfo))/2\n",
        "print(zero_perc,dfo['close'].quantile([0]+[i*(zero_perc-0.005)/9.5+0.005 for i in range(10)]+[0.995-(0.995-zero_perc)/10.5*(21-i) for i in range(11,22)]+[1]))\n",
        "boxplot(vars_h[1:],bad_value)\n",
        "boxplot([[f'{var}_{i+1}' for i in range(duration)] for var in vars_h[1:]],0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6hp-LUzQAtv"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_colwidth', None,'display.max_rows', None):\n",
        "  display(dfo[dfo['spot']>15].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6JlPEHHGZoQ"
      },
      "source": [
        "# run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cr_Pc_GGZoQ"
      },
      "outputs": [],
      "source": [
        "next_dep=0\n",
        "# resume=False#s\n",
        "# resume=True#False#\n",
        "# ignore_load_error=True\n",
        "# ignore_load_zero=True\n",
        "\n",
        "n_epochs = 2000\n",
        "n_trials = 80\n",
        "start_epoch = 1\n",
        "sub_epochs=15\n",
        "\n",
        "for dep_sec in range(next_dep, len(dep_vars)):\n",
        "    n_no_improve = 0\n",
        "    setup_data()\n",
        "    print(X['train'][0].shape, X['train'][1].shape, y['train'].shape)\n",
        "    validate()\n",
        "    resume=True\n",
        "    # report_frequency = len(X['train']) // batch_size // 5\n",
        "    for epoc in range(start_epoch, n_epochs , sub_epochs):\n",
        "      for epoch in range(epoc,epoc+sub_epochs):\n",
        "        for iteration, batch_idx in enumerate(train_loader):\n",
        "            my_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            x_batch = (X['train'][0][batch_idx] if len(cat_names)>0 else None,\n",
        "                       X['train'][1][batch_idx],\n",
        "                       X['train'][2][batch_idx])\n",
        "            y_batch = y['train'][batch_idx]\n",
        "            loss = loss_fn(\n",
        "                apply_model(my_model,\n",
        "                            x_cat=x_batch[0] if len(cat_names)>0 else None,\n",
        "                            x_num=x_batch[1], x2=x_batch[2]).squeeze(1),\n",
        "                y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # if iteration % report_frequency == 0:\n",
        "            #     print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
        "\n",
        "        val_score = evaluate()[0]\n",
        "        # test_score = evaluate(my_model,'test')[0]\n",
        "        print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f}', end=\" \")\n",
        "        progress.update(-val_score)\n",
        "        if progress.success:\n",
        "            print(' <<< BEST VALIDATION EPOCH')\n",
        "            save_model(True)\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            # save_model(False)\n",
        "            n_no_improve += 1\n",
        "            print(f' no improve {n_no_improve}')\n",
        "        if progress.fail or val_score < .01 or n_no_improve > n_trials:\n",
        "            break\n",
        "      if progress.fail or val_score < .01 or n_no_improve > n_trials:\n",
        "        break\n",
        "      if n_no_improve>sub_epochs:\n",
        "        setup_data(True)\n",
        "    load_model(load_good=True)\n",
        "    with open(mydrive + jobname, 'wb') as filehandler:\n",
        "        dump((my_model, y_std, y_mean, enc), filehandler)\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "644yutrlMd8A"
      },
      "source": [
        "## manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9xn0L0Mbhsy"
      },
      "outputs": [],
      "source": [
        "    #my_model, y_std, y_mean, enc = models\n",
        "    # setup_data(0)\n",
        "    prediction = []\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "      my_model.eval()\n",
        "      for batch in zero.iter_batches(X['test'], batch_size):\n",
        "      # batch=next(zero.iter_batches(X['test'], batch_size))\n",
        "      # if True:\n",
        "        prediction.append(apply_model(my_model,\n",
        "                                      x_cat=batch[0] if len(cat_names)>0 else None,\n",
        "                                      x_num=batch[1],x2=batch[2]))\n",
        "    prediction = torch.cat(prediction)\n",
        "    target = y['test']#[i:i+batch_size]\n",
        "    if task_type == 'binclass':\n",
        "      prediction = np.round(scipy.special.expit(prediction))\n",
        "      score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    elif task_type == 'multiclass':\n",
        "      prediction = prediction.argmax(1)\n",
        "      score = (target.reshape(-1)!=prediction).sum()/len(prediction)\n",
        "    else:\n",
        "      assert task_type == 'regression'\n",
        "      score =mse_loss_with_nans(prediction, target, ) ** 0.5\n",
        "\n",
        "    score,target, prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcG2MIhJ81WL"
      },
      "outputs": [],
      "source": [
        "for i in range(len(target)):\n",
        "  if target[i][0]==1 and prediction[i][0]>2:\n",
        "    print(i,target[i],prediction[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0zHlzwLU7YZ"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_colwidth', None,'display.max_rows', None):\n",
        "  display(dfo[(dfo['dtm']==1)&(dfo['diff_1']==19)&(dfo['dtm_1']==10)&(dfo['Horizon']<4)].iloc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX5LLv6mWCrU"
      },
      "outputs": [],
      "source": [
        "validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBiFUNvwMa74"
      },
      "source": [
        "## export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooKEpKisDJ_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a6d393-1fc2-4adb-a9f6-4c92fb088160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xci_close,hi torch.Size([17580, 20])\n",
            "PETrans 6 16 198 [] 41 2\n",
            "loaded Xci_close,hi epoch 335\n",
            "failed to load:  ('size diffs now', 1758, 25763)\n",
            "offset  12585\n"
          ]
        }
      ],
      "source": [
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "resume=True\n",
        "ignore_load_zero=True\n",
        "ignore_load_error=True\n",
        "\n",
        "if len(dep_vars)>0:\n",
        "  setup_data()\n",
        "  with open(mydrive + jobname, 'wb') as filehandler:\n",
        "      dump((my_model, y_std, y_mean, enc), filehandler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA3Aa0Mg2Dv1"
      },
      "source": [
        "# valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHQvL3Ea2Ga8"
      },
      "outputs": [],
      "source": [
        "last_run = \"2023-12-17\"\n",
        "next_run = \"2023-10-30\"\n",
        "\n",
        "def val_period(periods,source=None):\n",
        "    global jobname, X, y, my_model, y_mean, y_std\n",
        "    for period in periods:\n",
        "      print(period,'========================================================')\n",
        "      df = dfo.query(f'date>\"#{period[0]}\" and date<\"#{period[1]}\"')\n",
        "      if source:\n",
        "        df=df[df['source']==source]\n",
        "      if len(df)<1:\n",
        "        return\n",
        "      df.sort_values(by=['Horizon'],inplace=True)\n",
        "      dep_var=dep_vars[0]+dep_vars[1]\n",
        "      X, y = ({'test':\n",
        "                (  # dfo.loc[:,cat_names+vars_c+cont_names].to_numpy().astype('float32')},{}\n",
        "                    torch.tensor(df.loc[:, cat_names].to_numpy(), device=device).to(torch.int64),\n",
        "                    torch.tensor(df.loc[:, cont_names].to_numpy().astype('float32').reshape((df.shape[0], int(len(cont_names) / duration), duration)), device=device),\n",
        "                    torch.tensor(df.loc[:, vars_c].to_numpy().astype('float32'), device=device),\n",
        "                )\n",
        "                }, {'test': torch.tensor(df.loc[:,dep_var].to_numpy(), device=device).float()})\n",
        "      print('duration: ', duration,df.shape, X['test'][0].shape, X['test'][1].shape, X['test'][2].shape)\n",
        "      y['test'][:,-1]-=1\n",
        "\n",
        "      #for learner in models:\n",
        "      jobname = job_name()\n",
        "      my_model, y_std, y_mean, enc = models\n",
        "      y['test'][y['test']==bad_value]=float('nan')\n",
        "      cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "      y['test'][:,cols_to_norm]=((y['test']-y_mean) / y_std)[:,cols_to_norm].float()\n",
        "      score,target, prediction,prediction2 = evaluate(my_model,'test')\n",
        "      print(\"score\",score)\n",
        "      if score<20:\n",
        "        target, prediction, prediction2 = target.squeeze(1).cpu().numpy(), prediction.squeeze(1).cpu().numpy(), prediction2.cpu().numpy()\n",
        "        plot_result(target, prediction,prediction2)\n",
        "        if period[1]=='9999' or source is not None:\n",
        "          count=df.groupby(['Horizon'])['Horizon'].count().sort_index().cumsum()\n",
        "          count[-1]=0\n",
        "          mask=~np.isnan(target[:,:-1])\n",
        "          for h in range(6):\n",
        "            t,p,p2,m=target[count[h-1]:count[h],:], prediction[count[h-1]:count[h],:],prediction2[count[h-1]:count[h]],mask[count[h-1]:count[h],:]\n",
        "            if len(t)>10:\n",
        "              score = ((p[:,:-y_cat][m]-t[:,:-1][m])**2).mean()**.5*10+\\\n",
        "                      ((t[:,-1]!=p2).sum()/len(p))\n",
        "              print ('Horizon: ',h,'\\tScore:',score,len(t))\n",
        "              plot_result(t,p,p2,source is not None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dfo, cont_names = get_cont_names()\n",
        "# path=f'{mydrive}Xcj_close,hicheckpoint.pt'\n",
        "dfo.sort_values(by=['date'],inplace=True)\n",
        "path=mydrive+jobname+'checkpoint.pt'\n",
        "checkpoint = torch.load(path,map_location=device)\n",
        "offset,jobsize=checkpoint['offset'],checkpoint['jobsize']\n",
        "start,end=dfo['date'].iloc[offset],dfo['date'].iloc[offset+jobsize],\n",
        "print(f\"epoch {checkpoint['epoch']} jobsize {jobsize} to {len(dfo)//10} offset {start} {end}\")\n",
        "print(dfo.iloc[offset:offset+jobsize][['date','source','Horizon']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCILp1hVhgvt",
        "outputId": "9e51378a-3772-4159-f9f7-566872c70820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 29 jobsize 27099 to 27099 offset #2023-08-18 15:49:52# #2023-10-05 11:02:01#\n",
            "                         date      source  Horizon\n",
            "33244   #2023-08-18 15:49:52#  volcvA.csv        2\n",
            "33226   #2023-08-18 15:49:52#  volcvA.csv        2\n",
            "33495   #2023-08-18 15:49:52#  volcvA.csv        1\n",
            "32335   #2023-08-18 15:49:52#  volcvA.csv        5\n",
            "32605   #2023-08-18 15:49:52#  volcvA.csv        5\n",
            "...                       ...         ...      ...\n",
            "106920  #2023-10-05 11:02:01#  volcvT.csv        5\n",
            "108198  #2023-10-05 11:02:01#  volcvT.csv        1\n",
            "106822  #2023-10-05 11:02:01#  volcvT.csv        5\n",
            "107338  #2023-10-05 11:02:01#  volcvT.csv        4\n",
            "107726  #2023-10-05 11:02:01#  volcvT.csv        2\n",
            "\n",
            "[27099 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# jobname = 'Xcj_close,hi'\n",
        "jobname = job_name()\n",
        "with open(f'{mydrive}/{jobname}', 'rb') as filehandler:\n",
        "    models=load(filehandler)\n",
        "\n",
        "dfo, cont_names = get_cont_names()\n",
        "\n",
        "dfo['day']=dfo['date_6'].astype(int)\n",
        "lastday=dfo.groupby(['day','source'])['date_6'].transform(max)\n",
        "dfo=dfo[dfo['date_6']>lastday-0.02]\n",
        "\n",
        "enc=models[3]\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "\n",
        "y_cat=22\n",
        "for table in tables:\n",
        "  print(table)\n",
        "  val_period( [['2023-01-06','2023-01-20']],table)"
      ],
      "metadata": {
        "id": "OXOw-lgbmVX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3hAESRSRST1h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjTMlGKjcb1x"
      },
      "source": [
        "## before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtQdjLgiMBpw"
      },
      "outputs": [],
      "source": [
        "last_run = \"2023-12-17\"\n",
        "next_run = \"2023-10-30\"\n",
        "\n",
        "tables = ['volcvg.csv']\n",
        "mydrive= 'E:/mydoc/git/trade/analyics/'\n",
        "# \"\"\"\n",
        "tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "mydrive='/content/drive/MyDrive/volrt/'\n",
        "# Requirements:\n",
        "import os\n",
        "if not os.path.exists('/usr/local/lib/python3.10/dist-packages/rtdl'):\n",
        "  %pip install git+https://github.com/jerronl/rtdl.git\n",
        "#\"\"\"\n",
        "\n",
        "appname='Xcj_'\n",
        "duration = 6\n",
        "bad_value=-99999\n",
        "vars_h, cat_names, ys,vars_c,= (\n",
        "    ['date', 'diff', 'spot'],\n",
        "    [],\n",
        "    [[\n",
        "        'close', 'hi', 'lo',\n",
        "        'dtm','level','slope','curve',\n",
        "         'dtm1','level1','slope1','curve1',\n",
        "         'dtm2','level2','slope2','curve2',\n",
        "         'dtm3','level3','slope3','curve3'],\n",
        "         [ 'pmcat',],],\n",
        "    ['Horizon','spot','time'],\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "vars_h+=ys[0]\n",
        "dep_vars=ys#[duration]\n",
        "# vars_c=vars_c[duration]\n",
        "\n",
        "ignore_load_zero=ignore_load_error=y_std=y_mean=X=y=loss_fn=my_model=jobsize=offset=start_epoch=optimizer=rand_seed = None\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from typing import Any, Dict\n",
        "import rtdl\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import rtdl.zero as zero\n",
        "import matplotlib.pyplot as plt,os\n",
        "%matplotlib inline\n",
        "from typing import Optional\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from pickle import dump, load\n",
        "import seaborn as sns\n",
        "import random\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import xlrd\n",
        "from itertools import product\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.13-cp38-cp38-linux_x86_64.whl --force-reinstall\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "zero.improve_reproducibility(seed=1234567)\n",
        "batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*8\n",
        "print(f'GPU mem:{int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)}G, batch_size:{batch_size}')\n",
        "\n",
        "# =======================================================model=========================================\n",
        "def cyclic_encode(data,feature,original,period,names):\n",
        "  data[f'sin_{feature}'] = np.sin(2 * np.pi * original/period)\n",
        "  data[f'cos_{feature}'] = np.cos(2 * np.pi * original/period)\n",
        "  names.extend([f'sin_{feature}',f'cos_{feature}'])\n",
        "\n",
        "def get_cont_names(next_run=None):\n",
        "  cont_names, dfo  = [f'{x[0]}_{x[1]+1}' for x in product(vars_h,range(duration))], pd.DataFrame()\n",
        "  for table in tables:\n",
        "      df = pd.read_csv(mydrive + table)\n",
        "      if next_run:\n",
        "        df=df.query(f'date>\"#{next_run}\"')\n",
        "      df['source']=table\n",
        "      dfo = pd.concat([dfo, df])\n",
        "  dfo.sort_values(by=['date'],inplace=True)\n",
        "  for cyclic in ['date_1','date_2','date_3','date_4','date_5','date_6']:\n",
        "    cyclics=np.vectorize(lambda x: x.timetuple())(pd.to_datetime(dfo[cyclic], unit='D', origin='1899-12-30').astype('object'))\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  for cyclic in ['diff_1','diff_2','diff_3','diff_4','diff_5','diff_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],70,cont_names)\n",
        "  for cyclic in ['dtm_1','dtm_2','dtm_3','dtm_4','dtm_5','dtm_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],5,cont_names)\n",
        "  cont_names.sort()\n",
        "  for cyclic in ['date']:\n",
        "    cyclics=np.vectorize(lambda x: datetime(int(x[1:5]),int(x[6:8]),int(x[9:11]),int(x[12:14]),int(x[15:17]),int(x[18:20]),).timetuple())(dfo[cyclic])\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  assert len(cont_names) % 6==0\n",
        "  dfo['time']=np.modf(dfo['date_6'])[0]\n",
        "  return dfo, cont_names\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, position=None):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        if position is None:\n",
        "            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
        "        # Used for tensors that need to be on the same device as the module.\n",
        "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "class PETrans(nn.Module):\n",
        "\n",
        "    def __init__(self, duration, d_model,n_num_features,cat_cardinalities,d_out,x2):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        print(\"PETrans\",duration, d_model,n_num_features,cat_cardinalities,d_out,x2)\n",
        "        super().__init__()\n",
        "        # Input dim -> Model dim\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Linear(duration, d_model*2), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Dropout(0.1), #self.hparams.input_dropout),\n",
        "            nn.GELU(), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Linear(d_model*2, d_model), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "        )\n",
        "        # Positional encoding for sequences\n",
        "        self.positional_encoding = PositionalEncoding(d_model=d_model)\n",
        "        self.unf=nn.Flatten(1,2)\n",
        "        self.ftt= rtdl.FTTransformer.make_default(\n",
        "            n_num_features=int(n_num_features/duration*d_model+x2),\n",
        "            cat_cardinalities=cat_cardinalities,\n",
        "            d_out=d_out,\n",
        "            )\n",
        "\n",
        "    def forward(self, x_num: Optional[Tensor], x_cat: Optional[Tensor], x2: Optional[Tensor]) -> Tensor:\n",
        "        x = self.input_net(x_num)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.unf(x)\n",
        "        x = torch.cat((x, x2), 1)\n",
        "        x = self.ftt(x, x_cat)\n",
        "        return x\n",
        "\n",
        "    def make_default_optimizer(self) -> torch.optim.AdamW:\n",
        "        \"\"\"Make the optimizer for the default FT-Transformer.\"\"\"\n",
        "        return self.ftt.make_default_optimizer()\n",
        "\n",
        "def apply_model(model, x_num, x_cat=None, x2=None):\n",
        "    return model(x_num, x_cat, x2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mload=None,part='val'):\n",
        "    model=mload or my_model\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], batch_size):\n",
        "        prediction.append(apply_model(model,\n",
        "                                      x_cat=batch[0] if len(cat_names)>0 else None,\n",
        "                                      x_num=batch[1],x2=batch[2]))\n",
        "    prediction = torch.cat(prediction)\n",
        "    target = y[part]\n",
        "    prediction2 = prediction[:,-y_cat:].argmax(1)\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    score = (F.mse_loss(prediction[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "          ((target[:,-1]!=prediction2).sum()/len(prediction))\n",
        "\n",
        "    return score,target, prediction,prediction2\n",
        "\n",
        "def plot_result(target, prediction, prediction2, compare=False):\n",
        "  sns.jointplot(x=target[:,-1] , y=prediction2,kind=\"kde\",fill=True,rug=True)\n",
        "  prediction[:,-y_cat]=prediction2\n",
        "  sns.set(style=\"whitegrid\")\n",
        "  print(f'mse={np.mean((target[:,-1] - prediction2)**2)}')\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  figs=min(len(dep_var),4)\n",
        "  _, axes = plt.subplots(math.ceil(len(dep_var)/figs), figs, figsize=(16,16))\n",
        "  for i,name in enumerate(dep_var):\n",
        "      axs=axes.flat[i] if figs>1 else axes\n",
        "      sns.regplot(ax=axs, x=target[:,i] , y=prediction[:,i],\n",
        "                scatter_kws = {'color': 'purple', 'alpha': 0.3},\n",
        "                line_kws = {'color': '#CCCC00', 'alpha': 0.3}\n",
        "                )\n",
        "      axs.set_title(name)\n",
        "      mask=~np.isnan(target[:,i])\n",
        "      if len(target[:,i][mask])>0:\n",
        "        if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "\n",
        "          axs.set_xlim(left=max(np.min(target[:,i][mask]), -2.5),\n",
        "                        right=min(np.max(target[:,i][mask]),2.5))\n",
        "        else:\n",
        "          axs.set_xlim(left=np.min(target[:,i][mask]),\n",
        "                              right=np.max(target[:,i][mask]))\n",
        "  plt.show()\n",
        "  if compare:\n",
        "    for i,name in enumerate(dep_var):\n",
        "      if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "        plt.plot(target[:,i],label=f'actual {name}')\n",
        "        plt.plot(prediction[:,i],label=f'forecast {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(mload=None, threshold=10):\n",
        "  score,target, prediction,prediction2 = evaluate(mload,'test')\n",
        "  print(jobname,f'{score:.4f}')\n",
        "  if score>threshold:\n",
        "    return\n",
        "  target, prediction, prediction2 = target.squeeze(1).cpu().numpy(), prediction.squeeze(1).cpu().numpy(), prediction2.cpu().numpy()\n",
        "  plot_result(target, prediction,prediction2)\n",
        "\n",
        "def cross_entropy_mse_loss_with_nans(input, target):\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    return (F.mse_loss(input[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "      (F.cross_entropy (input[:,-y_cat:],target[:,-1].type(torch.LongTensor).to(device)))\n",
        "\n",
        "def model_path():\n",
        "  return mydrive+jobname+'checkpoint.pt'\n",
        "\n",
        "def save_model(improved=False):\n",
        "  path=mydrive+jobname+'checkpoint.pt'\n",
        "  torch.save(\n",
        "      {\n",
        "          'model_':  my_model.state_dict() if improved or not os.path.exists(path) else\n",
        "                    torch.load(path)['model_'],\n",
        "          'model'       : my_model.state_dict(),\n",
        "          'optimizer'   : optimizer.state_dict(),\n",
        "          'epoch'       : epoch,\n",
        "          'random_state': zero.random.get_state (),\n",
        "          'jobsize'     : jobsize,\n",
        "          'offset'      : offset,\n",
        "          'rand_seed'    : rand_seed,\n",
        "      },\n",
        "      path\n",
        "  )\n",
        "\n",
        "def load_model(load_good=False,keep_seed=True):\n",
        "  global jobsize,offset,start_epoch,my_model,optimizer,rand_seed\n",
        "  start_epoch=1\n",
        "  jobsize=int(len(X_all)*0.1)\n",
        "  if resume:\n",
        "    path=mydrive+jobname+'checkpoint.pt'\n",
        "    if os.path.exists(path):\n",
        "      try:\n",
        "        checkpoint = torch.load(path,map_location=device)\n",
        "        my_model.load_state_dict(checkpoint['model_'if load_good else 'model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        if 'rand_seed' in checkpoint and keep_seed:\n",
        "          rand_seed=checkpoint['rand_seed']\n",
        "        try:\n",
        "          zero.random.set_state(checkpoint['random_state'])\n",
        "        except (AssertionError,) as err:\n",
        "          if ignore_load_zero:\n",
        "            print(\"zero error:\",err)\n",
        "          else:\n",
        "            raise err\n",
        "        print(f'loaded {jobname} epoch {start_epoch}')\n",
        "        if 'jobsize' in checkpoint and checkpoint['jobsize']<=jobsize:\n",
        "          offset=checkpoint['offset']\n",
        "          if checkpoint['jobsize']<jobsize:\n",
        "            print('Job size increased from ', checkpoint['jobsize'], ' to ', jobsize)\n",
        "            if offset<0:\n",
        "              offset+=checkpoint['jobsize']*10\n",
        "        else:\n",
        "          raise ValueError('size diffs now',jobsize,\n",
        "                checkpoint['jobsize'] if 'jobsize' in checkpoint else 0)\n",
        "        return True\n",
        "      except Exception as error:\n",
        "        if ignore_load_error:\n",
        "          print(\"failed to load: \", error)\n",
        "        else:\n",
        "          raise error\n",
        "  random.seed(datetime.now().timestamp())\n",
        "  offset=random.randint(-jobsize*3,-jobsize*2)+jobsize*10\n",
        "  return False\n",
        "\n",
        "def job_name():\n",
        "  return appname+''.join(filter(lambda x: x not in \"[' \", str(dep_vars[0])))[:8]\n",
        "\n",
        "def setup_data(mis=False):\n",
        "  global jobname,X,y, my_model,optimizer,train_loader,progress,y_mean,y_std,loss_fn,y_cat,rand_seed\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  jobname=job_name()\n",
        "  y_all=torch.tensor(dfo.loc[:,dep_var].to_numpy(), device=device)\n",
        "\n",
        "  y_cat = 22#int(max(y_all[:,-1]))\n",
        "  y_all[:,-1]-=1\n",
        "  d_out = y_cat+y_all.shape[1]-1\n",
        "\n",
        "  X,y = {},{}\n",
        "  my_model=PETrans(\n",
        "      duration=duration,\n",
        "      d_model=16,\n",
        "      n_num_features=len(cont_names),\n",
        "      cat_cardinalities=[len(arr) for arr in enc.categories_],\n",
        "      d_out=d_out,\n",
        "      x2=len(vars_c)\n",
        "      ).to(device)\n",
        "\n",
        "  optimizer = (\n",
        "      my_model.make_default_optimizer()\n",
        "  )\n",
        "  load_model(load_good=mis,keep_seed= not mis)\n",
        "\n",
        "  X['train'], X['test'], y['train'], y['test']  = (\n",
        "      np.concatenate((X_all[:offset],X_all[offset+jobsize:])),\n",
        "      X_all[offset:offset+jobsize],\n",
        "      torch.cat((y_all[:offset],y_all[offset+jobsize:])),\n",
        "      y_all[offset:offset+jobsize],\n",
        "  )\n",
        "  if rand_seed is None:\n",
        "    rand_seed=np.random.default_rng().integers(99999)\n",
        "  print(jobname,y_all.shape,'offset ',offset,dfo['date'].iloc[offset],'seed', rand_seed)\n",
        "  X['train'], X['val'],  y['train'], y['val']  = sklearn.model_selection.train_test_split(\n",
        "      X['train'], y['train'], train_size=0.95, random_state=rand_seed\n",
        "  )\n",
        "  X2, X['test'], y2, y['test']  = sklearn.model_selection.train_test_split(\n",
        "      X['test'], y['test'], train_size=0.05, random_state=rand_seed\n",
        "  )\n",
        "  X['val'], y['val']=np.concatenate((X['val'], X['test'])),torch.cat(( y['val'], y['test']))\n",
        "  X['train'], y['train']=np.concatenate((X['train'], X2)),torch.cat(( y['train'], y2))\n",
        "\n",
        "  X = {\n",
        "      k: (torch.tensor(v[:,:len(cat_names)], device=device).to(torch.int64),\n",
        "          torch.tensor(v[:,-len(cont_names):].reshape((v.shape[0],int(len(cont_names)/duration),duration)), device=device),\n",
        "          torch.tensor(v[:,len(cat_names):-len(cont_names)], device=device),)\n",
        "      for k, v in X.items()\n",
        "  }\n",
        "  # y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "  mask=torch.masked.masked_tensor(y['train'],y['train']!=bad_value)\n",
        "  y_mean,y_std=mask.mean(dim=0).to_tensor(0),mask.std(dim=0).to_tensor(0)\n",
        "  cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "  for k,v in y.items():\n",
        "    v[v==bad_value]=float('nan')\n",
        "    v[:,cols_to_norm]=((v-y_mean) / y_std)[:,cols_to_norm]\n",
        "    y[k]=v\n",
        "\n",
        "\n",
        "  y = {k: v.float() for k, v in y.items()}\n",
        "\n",
        "  train_loader = zero.data.IndexLoader(len(X['train'][0]), batch_size, device=device)\n",
        "  progress = zero.ProgressTracker(patience=100)\n",
        "  loss_fn = cross_entropy_mse_loss_with_nans\n",
        "\n",
        "def boxplot(vars,bad_value=None):\n",
        "  i=j=min(5,len(vars))\n",
        "  for _,var in enumerate(vars):\n",
        "      if isinstance(var,list):\n",
        "        y=pd.Series()\n",
        "        for name in var:\n",
        "          if name in dfo.columns:\n",
        "            y=y.append(dfo[name],ignore_index = True)\n",
        "      else:\n",
        "        y=dfo[var] if var in dfo.columns else []\n",
        "        name=var\n",
        "      if len(y)>0:\n",
        "        if i>=j:\n",
        "          figure, axes = plt.subplots(1,j,figsize=(16,8))\n",
        "          i=0\n",
        "        axs=axes.flat[i]\n",
        "        i+=1\n",
        "        if bad_value is not None and y.min()<=bad_value:\n",
        "          mask=y!=bad_value\n",
        "          name=f'{name}_{mask.sum()/len(mask):.0%}'\n",
        "          y=y[mask]\n",
        "        sns.boxplot(ax=axs, y=y, showmeans=True,\n",
        "                          meanprops={\"marker\": \"+\",\n",
        "                        \"markeredgecolor\": \"black\",\n",
        "                        \"markersize\": \"10\"})\n",
        "        axs.set_title(name)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def set_state(state: Dict[str, Any]) -> None:\n",
        "    \"\"\"Set global random states in `random`, `numpy` and `torch`.\n",
        "\n",
        "    Args:\n",
        "        state: global RNG states. Must be produced by `get_state`. The size of the list\n",
        "            :code:`state['torch.cuda']` must be equal to the number of available cuda\n",
        "            devices.\n",
        "\n",
        "    See also:\n",
        "        `get_state`\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: if :code:`torch.cuda.device_count() != len(state['torch.cuda'])`\n",
        "    \"\"\"\n",
        "    random.setstate(state['random'])\n",
        "    np.random.set_state(state['numpy.random'])\n",
        "    torch.random.set_rng_state(state['torch.random'].cpu())\n",
        "    assert torch.cuda.device_count() == len(state['torch.cuda'])\n",
        "    torch.cuda.set_rng_state_all([v.cpu() for v in state['torch.cuda']])  # type: ignore\n",
        "\n",
        "zero.random.set_state=set_state\n",
        "\n",
        "#====================================================train=================================\n",
        "# next_dep = 0\n",
        "# next_dep=1\n",
        "# next_dep=2\n",
        "# next_dep=3\n",
        "resume = True  # False#\n",
        "# tables = ['volcva.csv']\n",
        "# tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "dfo, cont_names=get_cont_names()\n",
        "\n",
        "dfo.sort_values(by=['date'],inplace=True)\n",
        "enc = OrdinalEncoder()\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "\n",
        "print(dfo.shape, X_all.shape,len(dep_vars[0]))\n",
        "zero_perc=(1-len(dfo[dfo['close']>0])/len(dfo)+len(dfo[dfo['close']<0])/len(dfo))/2\n",
        "print(zero_perc,dfo['close'].quantile([0]+[i*(zero_perc-0.005)/9.5+0.005 for i in range(10)]+[0.995-(0.995-zero_perc)/10.5*(21-i) for i in range(11,22)]+[1]))\n",
        "\n",
        "#=====================================================export====================================\n",
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "resume=True\n",
        "ignore_load_zero=True\n",
        "ignore_load_error=True\n",
        "\n",
        "if len(dep_vars)>0:\n",
        "  setup_data()\n",
        "  with open(mydrive + jobname, 'wb') as filehandler:\n",
        "      dump((my_model, y_std, y_mean, enc), filehandler)\n",
        "\n",
        "validate(threshold=20)\n",
        "#=========================================valid=======================\n",
        "jobname = job_name()\n",
        "with open(f'{mydrive}/{jobname}', 'rb') as filehandler:\n",
        "    models=load(filehandler)\n",
        "\n",
        "dfo, cont_names = get_cont_names(next_run)\n",
        "\n",
        "enc=models[3]\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "y_cat=22\n",
        "\n",
        "def val_period(periods,source=None):\n",
        "    global jobname, X, y, my_model, y_mean, y_std\n",
        "    for period in periods:\n",
        "      print(period,'========================================================')\n",
        "      df = dfo.query(f'date>\"#{period[0]}\" and date<\"#{period[1]}\"')\n",
        "      if source:\n",
        "        df=df[df['source']==source]\n",
        "      if len(df)<1:\n",
        "        return\n",
        "      df.sort_values(by=['Horizon'],inplace=True)\n",
        "      dep_var=dep_vars[0]+dep_vars[1]\n",
        "      X, y = ({'test':\n",
        "                (  # dfo.loc[:,cat_names+vars_c+cont_names].to_numpy().astype('float32')},{}\n",
        "                    torch.tensor(df.loc[:, cat_names].to_numpy(), device=device).to(torch.int64),\n",
        "                    torch.tensor(df.loc[:, cont_names].to_numpy().astype('float32').reshape((df.shape[0], int(len(cont_names) / duration), duration)), device=device),\n",
        "                    torch.tensor(df.loc[:, vars_c].to_numpy().astype('float32'), device=device),\n",
        "                )\n",
        "                }, {'test': torch.tensor(df.loc[:,dep_var].to_numpy(), device=device).float()})\n",
        "      print('duration: ', duration,df.shape, X['test'][0].shape, X['test'][1].shape, X['test'][2].shape)\n",
        "      y['test'][:,-1]-=1\n",
        "\n",
        "      #for learner in models:\n",
        "      jobname = job_name()\n",
        "      my_model, y_std, y_mean, enc = models\n",
        "      y['test'][y['test']==bad_value]=float('nan')\n",
        "      cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "      y['test'][:,cols_to_norm]=((y['test']-y_mean) / y_std)[:,cols_to_norm].float()\n",
        "      score,target, prediction,prediction2 = evaluate(my_model,'test')\n",
        "      print(\"score\",score)\n",
        "      if score<20:\n",
        "        target, prediction, prediction2 = target.squeeze(1).cpu().numpy(), prediction.squeeze(1).cpu().numpy(), prediction2.cpu().numpy()\n",
        "        plot_result(target, prediction,prediction2)\n",
        "        if period[1]=='9999' or source is not None:\n",
        "          count=df.groupby(['Horizon'])['Horizon'].count().sort_index().cumsum()\n",
        "          count[-1]=0\n",
        "          mask=~np.isnan(target[:,:-1])\n",
        "          for h in range(6):\n",
        "            t,p,p2,m=target[count[h-1]:count[h],:], prediction[count[h-1]:count[h],:],prediction2[count[h-1]:count[h]],mask[count[h-1]:count[h],:]\n",
        "            if len(t)>10:\n",
        "              score = ((p[:,:-y_cat][m]-t[:,:-1][m])**2).mean()**.5*10+\\\n",
        "                      ((t[:,-1]!=p2).sum()/len(p))\n",
        "              print ('Horizon: ',h,'\\tScore:',score,len(t))\n",
        "              plot_result(t,p,p2,source is not None)\n",
        "val_period( [[last_run, '9999'], [next_run, last_run]])\n",
        "\n",
        "dfo['day']=dfo['date_6'].astype(int)\n",
        "lastday=dfo.groupby(['day','source'])['date_6'].transform(max)\n",
        "dfo=dfo[dfo['date_6']>lastday-0.02]\n",
        "\n",
        "\n",
        "for table in tables:\n",
        "  print(table)\n",
        "  val_period( [[last_run, '9999'], [next_run, last_run]],table)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfo, cont_names=get_cont_names()\n",
        "\n",
        "dfo.sort_values(by=['date'],inplace=True)\n",
        "enc = OrdinalEncoder()\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "\n",
        "print(dfo.shape, X_all.shape,len(dep_vars[0]))\n",
        "zero_perc=(1-len(dfo[dfo['close']>0])/len(dfo)+len(dfo[dfo['close']<0])/len(dfo))/2\n",
        "print(zero_perc,dfo['close'].quantile([0]+[i*(zero_perc-0.005)/9.5+0.005 for i in range(10)]+[0.995-(0.995-zero_perc)/10.5*(21-i) for i in range(11,22)]+[1]))\n",
        "boxplot(vars_h[1:],bad_value)\n",
        "boxplot([[f'{var}_{i+1}' for i in range(duration)] for var in vars_h[1:]],0)\n"
      ],
      "metadata": {
        "id": "pm193qtZJBR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEO9_yN9Q7to"
      },
      "source": [
        "## after"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_period()"
      ],
      "metadata": {
        "id": "oK8SGvx1vDdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkw9ts8N3ZM-"
      },
      "source": [
        "# all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxqRgl6s3bkB"
      },
      "outputs": [],
      "source": [
        "tables = ['volcvg.csv']\n",
        "mydrive= 'E:/mydoc/git/trade/analyics/'\n",
        "# \"\"\"\n",
        "tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "mydrive='/content/drive/MyDrive/volrt/'\n",
        "# Requirements:\n",
        "import os\n",
        "if not os.path.exists('/usr/local/lib/python3.10/dist-packages/rtdl'):\n",
        "  %pip install git+https://github.com/jerronl/rtdl.git\n",
        "#\"\"\"\n",
        "\n",
        "appname='Xcj_'\n",
        "duration = 6\n",
        "bad_value=-99999\n",
        "vars_h, cat_names, ys,vars_c,= (\n",
        "    ['date', 'diff', 'spot'],\n",
        "    [],\n",
        "    [[\n",
        "        'close', 'hi', 'lo',\n",
        "        'dtm','level','slope','curve',\n",
        "         'dtm1','level1','slope1','curve1',\n",
        "         'dtm2','level2','slope2','curve2',\n",
        "         'dtm3','level3','slope3','curve3'],\n",
        "         [ 'pmcat',],],\n",
        "    ['Horizon','spot','time'],\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "vars_h+=ys[0]\n",
        "dep_vars=ys#[duration]\n",
        "# vars_c=vars_c[duration]\n",
        "\n",
        "ignore_load_zero=ignore_load_error=y_std=y_mean=X=y=loss_fn=my_model=jobsize=offset=start_epoch=optimizer=rand_seed = None\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from typing import Any, Dict\n",
        "import rtdl\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import rtdl.zero as zero\n",
        "import matplotlib.pyplot as plt,os\n",
        "%matplotlib inline\n",
        "from typing import Optional\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from pickle import dump, load\n",
        "import seaborn as sns\n",
        "import random\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import xlrd\n",
        "from itertools import product\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.13-cp38-cp38-linux_x86_64.whl --force-reinstall\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "zero.improve_reproducibility(seed=1234567)\n",
        "batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*8\n",
        "print(f'GPU mem:{int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)}G, batch_size:{batch_size}')\n",
        "\n",
        "# =======================================================model=========================================\n",
        "def cyclic_encode(data,feature,original,period,names):\n",
        "  data[f'sin_{feature}'] = np.sin(2 * np.pi * original/period)\n",
        "  data[f'cos_{feature}'] = np.cos(2 * np.pi * original/period)\n",
        "  names.extend([f'sin_{feature}',f'cos_{feature}'])\n",
        "\n",
        "def get_cont_names(next_run=None):\n",
        "  cont_names, dfo  = [f'{x[0]}_{x[1]+1}' for x in product(vars_h,range(duration))], pd.DataFrame()\n",
        "  for table in tables:\n",
        "      df = pd.read_csv(mydrive + table)\n",
        "      if next_run:\n",
        "        df=df.query(f'date>\"#{next_run}\"')\n",
        "      df['source']=table\n",
        "      dfo = pd.concat([dfo, df])\n",
        "  dfo.sort_values(by=['date'],inplace=True)\n",
        "  for cyclic in ['date_1','date_2','date_3','date_4','date_5','date_6']:\n",
        "    cyclics=np.vectorize(lambda x: x.timetuple())(pd.to_datetime(dfo[cyclic], unit='D', origin='1899-12-30').astype('object'))\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  for cyclic in ['diff_1','diff_2','diff_3','diff_4','diff_5','diff_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],70,cont_names)\n",
        "  for cyclic in ['dtm_1','dtm_2','dtm_3','dtm_4','dtm_5','dtm_6']:\n",
        "    cyclic_encode(dfo,cyclic,dfo[cyclic],5,cont_names)\n",
        "  cont_names.sort()\n",
        "  for cyclic in ['date']:\n",
        "    cyclics=np.vectorize(lambda x: datetime(int(x[1:5]),int(x[6:8]),int(x[9:11]),int(x[12:14]),int(x[15:17]),int(x[18:20]),).timetuple())(dfo[cyclic])\n",
        "    cyclic_encode(dfo,f'y_{cyclic}',cyclics[7]-1,\n",
        "      np.vectorize(lambda x: 365-28+calendar.monthrange(x,2)[1])(cyclics[0]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'm_{cyclic}',cyclics[2]-1,\n",
        "      np.vectorize(lambda x,y: calendar.monthrange(x,y)[1])(cyclics[0],cyclics[1]),\n",
        "      cont_names)\n",
        "    cyclic_encode(dfo,f'w_{cyclic}',cyclics[6],7,cont_names)\n",
        "  assert len(cont_names) % 6==0\n",
        "  dfo['time']=np.modf(dfo['date_6'])[0]\n",
        "  return dfo, cont_names\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, position=None):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        if position is None:\n",
        "            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
        "        # Used for tensors that need to be on the same device as the module.\n",
        "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
        "        self.register_buffer('pe', pe, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "class PETrans(nn.Module):\n",
        "\n",
        "    def __init__(self, duration, d_model,n_num_features,cat_cardinalities,d_out,x2):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            max_len - Maximum length of a sequence to expect.\n",
        "        \"\"\"\n",
        "        print(\"PETrans\",duration, d_model,n_num_features,cat_cardinalities,d_out,x2)\n",
        "        super().__init__()\n",
        "        # Input dim -> Model dim\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Linear(duration, d_model*2), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Dropout(0.1), #self.hparams.input_dropout),\n",
        "            nn.GELU(), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "            nn.Linear(d_model*2, d_model), # self.hparams.input_dim, self.hparams.model_dim)\n",
        "        )\n",
        "        # Positional encoding for sequences\n",
        "        self.positional_encoding = PositionalEncoding(d_model=d_model)\n",
        "        self.unf=nn.Flatten(1,2)\n",
        "        self.ftt= rtdl.FTTransformer.make_default(\n",
        "            n_num_features=int(n_num_features/duration*d_model+x2),\n",
        "            cat_cardinalities=cat_cardinalities,\n",
        "            d_out=d_out,\n",
        "            )\n",
        "\n",
        "    def forward(self, x_num: Optional[Tensor], x_cat: Optional[Tensor], x2: Optional[Tensor]) -> Tensor:\n",
        "        x = self.input_net(x_num)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.unf(x)\n",
        "        x = torch.cat((x, x2), 1)\n",
        "        x = self.ftt(x, x_cat)\n",
        "        return x\n",
        "\n",
        "    def make_default_optimizer(self) -> torch.optim.AdamW:\n",
        "        \"\"\"Make the optimizer for the default FT-Transformer.\"\"\"\n",
        "        return self.ftt.make_default_optimizer()\n",
        "\n",
        "def apply_model(model, x_num, x_cat=None, x2=None):\n",
        "    return model(x_num, x_cat, x2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(mload=None,part='val'):\n",
        "    model=mload or my_model\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], batch_size):\n",
        "        prediction.append(apply_model(model,\n",
        "                                      x_cat=batch[0] if len(cat_names)>0 else None,\n",
        "                                      x_num=batch[1],x2=batch[2]))\n",
        "    prediction = torch.cat(prediction)\n",
        "    target = y[part]\n",
        "    prediction2 = prediction[:,-y_cat:].argmax(1)\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    score = (F.mse_loss(prediction[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "          ((target[:,-1]!=prediction2).sum()/len(prediction))\n",
        "\n",
        "    return score,target, prediction,prediction2\n",
        "\n",
        "def plot_result(target, prediction, prediction2, compare=False):\n",
        "  sns.jointplot(x=target[:,-1] , y=prediction2,kind=\"kde\",fill=True,rug=True)\n",
        "  prediction[:,-y_cat]=prediction2\n",
        "  sns.set(style=\"whitegrid\")\n",
        "  print(f'mse={np.mean((target[:,-1] - prediction2)**2)}')\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  figs=min(len(dep_var),4)\n",
        "  _, axes = plt.subplots(math.ceil(len(dep_var)/figs), figs, figsize=(16,16))\n",
        "  for i,name in enumerate(dep_var):\n",
        "      axs=axes.flat[i] if figs>1 else axes\n",
        "      sns.regplot(ax=axs, x=target[:,i] , y=prediction[:,i],\n",
        "                scatter_kws = {'color': 'purple', 'alpha': 0.3},\n",
        "                line_kws = {'color': '#CCCC00', 'alpha': 0.3}\n",
        "                )\n",
        "      axs.set_title(name)\n",
        "      mask=~np.isnan(target[:,i])\n",
        "      if len(target[:,i][mask])>0:\n",
        "        if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "\n",
        "          axs.set_xlim(left=max(np.min(target[:,i][mask]), -2.5),\n",
        "                        right=min(np.max(target[:,i][mask]),2.5))\n",
        "        else:\n",
        "          axs.set_xlim(left=np.min(target[:,i][mask]),\n",
        "                              right=np.max(target[:,i][mask]))\n",
        "  plt.show()\n",
        "  if compare:\n",
        "    for i,name in enumerate(dep_var):\n",
        "      if not dep_var[i][:3] in ['dtm','pmc']:\n",
        "        plt.plot(target[:,i],label=f'actual {name}')\n",
        "        plt.plot(prediction[:,i],label=f'forecast {name}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(mload=None, threshold=10):\n",
        "  score,target, prediction,prediction2 = evaluate(mload,'test')\n",
        "  print(jobname,f'{score:.4f}')\n",
        "  if score>threshold:\n",
        "    return\n",
        "  target, prediction, prediction2 = target.squeeze(1).cpu().numpy(), prediction.squeeze(1).cpu().numpy(), prediction2.cpu().numpy()\n",
        "  plot_result(target, prediction,prediction2)\n",
        "\n",
        "def cross_entropy_mse_loss_with_nans(input, target):\n",
        "    mask = ~torch.isnan(target[:,:-1])\n",
        "    return (F.mse_loss(input[:,:-y_cat][mask],target[:,:-1][mask])**.5)*10+\\\n",
        "      (F.cross_entropy (input[:,-y_cat:],target[:,-1].type(torch.LongTensor).to(device)))\n",
        "\n",
        "def model_path():\n",
        "  return mydrive+jobname+'checkpoint.pt'\n",
        "\n",
        "def save_model(improved=False):\n",
        "  path=mydrive+jobname+'checkpoint.pt'\n",
        "  torch.save(\n",
        "      {\n",
        "          'model_':  my_model.state_dict() if improved or not os.path.exists(path) else\n",
        "                    torch.load(path)['model_'],\n",
        "          'model'       : my_model.state_dict(),\n",
        "          'optimizer'   : optimizer.state_dict(),\n",
        "          'epoch'       : epoch,\n",
        "          'random_state': zero.random.get_state (),\n",
        "          'jobsize'     : jobsize,\n",
        "          'offset'      : offset,\n",
        "          'rand_seed'    : rand_seed,\n",
        "      },\n",
        "      path\n",
        "  )\n",
        "\n",
        "def load_model(load_good=False,keep_seed=True):\n",
        "  global jobsize,offset,start_epoch,my_model,optimizer,rand_seed\n",
        "  start_epoch=1\n",
        "  jobsize=int(len(X_all)*0.1)\n",
        "  if resume:\n",
        "    path=mydrive+jobname+'checkpoint.pt'\n",
        "    if os.path.exists(path):\n",
        "      try:\n",
        "        checkpoint = torch.load(path,map_location=device)\n",
        "        my_model.load_state_dict(checkpoint['model_'if load_good else 'model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        if 'rand_seed' in checkpoint and keep_seed:\n",
        "          rand_seed=checkpoint['rand_seed']\n",
        "        try:\n",
        "          zero.random.set_state(checkpoint['random_state'])\n",
        "        except (AssertionError,) as err:\n",
        "          if ignore_load_zero:\n",
        "            print(\"zero error:\",err)\n",
        "          else:\n",
        "            raise err\n",
        "        print(f'loaded {jobname} epoch {start_epoch}')\n",
        "        if 'jobsize' in checkpoint and checkpoint['jobsize']<=jobsize:\n",
        "          offset=checkpoint['offset']\n",
        "          if checkpoint['jobsize']<jobsize:\n",
        "            print('Job size increased from ', checkpoint['jobsize'], ' to ', jobsize)\n",
        "            if offset<0:\n",
        "              offset+=checkpoint['jobsize']*10\n",
        "        else:\n",
        "          raise ValueError('size diffs now',jobsize,\n",
        "                checkpoint['jobsize'] if 'jobsize' in checkpoint else 0)\n",
        "        return True\n",
        "      except Exception as error:\n",
        "        if ignore_load_error:\n",
        "          print(\"failed to load: \", error)\n",
        "        else:\n",
        "          raise error\n",
        "  random.seed(datetime.now().timestamp())\n",
        "  offset=random.randint(-jobsize*3,-jobsize*2)+jobsize*10\n",
        "  return False\n",
        "\n",
        "def job_name():\n",
        "  return appname+''.join(filter(lambda x: x not in \"[' \", str(dep_vars[0])))[:8]\n",
        "\n",
        "def setup_data(mis=False):\n",
        "  global jobname,X,y, my_model,optimizer,train_loader,progress,y_mean,y_std,loss_fn,y_cat,rand_seed\n",
        "  dep_var=dep_vars[0]+dep_vars[1]\n",
        "  jobname=job_name()\n",
        "  y_all=torch.tensor(dfo.loc[:,dep_var].to_numpy(), device=device)\n",
        "\n",
        "  y_cat = 22#int(max(y_all[:,-1]))\n",
        "  y_all[:,-1]-=1\n",
        "  d_out = y_cat+y_all.shape[1]-1\n",
        "\n",
        "  X,y = {},{}\n",
        "  my_model=PETrans(\n",
        "      duration=duration,\n",
        "      d_model=16,\n",
        "      n_num_features=len(cont_names),\n",
        "      cat_cardinalities=[len(arr) for arr in enc.categories_],\n",
        "      d_out=d_out,\n",
        "      x2=len(vars_c)\n",
        "      ).to(device)\n",
        "\n",
        "  optimizer = (\n",
        "      my_model.make_default_optimizer()\n",
        "  )\n",
        "  load_model(load_good=mis,keep_seed= not mis)\n",
        "\n",
        "  X['train'], X['test'], y['train'], y['test']  = (\n",
        "      np.concatenate((X_all[:offset],X_all[offset+jobsize:])),\n",
        "      X_all[offset:offset+jobsize],\n",
        "      torch.cat((y_all[:offset],y_all[offset+jobsize:])),\n",
        "      y_all[offset:offset+jobsize],\n",
        "  )\n",
        "  if rand_seed is None:\n",
        "    rand_seed=np.random.default_rng().integers(99999)\n",
        "  print(jobname,y_all.shape,'offset ',offset,dfo['date'].iloc[offset],'seed', rand_seed)\n",
        "  X['train'], X['val'],  y['train'], y['val']  = sklearn.model_selection.train_test_split(\n",
        "      X['train'], y['train'], train_size=0.95, random_state=rand_seed\n",
        "  )\n",
        "  X2, X['test'], y2, y['test']  = sklearn.model_selection.train_test_split(\n",
        "      X['test'], y['test'], train_size=0.05, random_state=rand_seed\n",
        "  )\n",
        "  X['val'], y['val']=np.concatenate((X['val'], X['test'])),torch.cat(( y['val'], y['test']))\n",
        "  X['train'], y['train']=np.concatenate((X['train'], X2)),torch.cat(( y['train'], y2))\n",
        "\n",
        "  X = {\n",
        "      k: (torch.tensor(v[:,:len(cat_names)], device=device).to(torch.int64),\n",
        "          torch.tensor(v[:,-len(cont_names):].reshape((v.shape[0],int(len(cont_names)/duration),duration)), device=device),\n",
        "          torch.tensor(v[:,len(cat_names):-len(cont_names)], device=device),)\n",
        "      for k, v in X.items()\n",
        "  }\n",
        "  # y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "  mask=torch.masked.masked_tensor(y['train'],y['train']!=bad_value)\n",
        "  y_mean,y_std=mask.mean(dim=0).to_tensor(0),mask.std(dim=0).to_tensor(0)\n",
        "  cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "  for k,v in y.items():\n",
        "    v[v==bad_value]=float('nan')\n",
        "    v[:,cols_to_norm]=((v-y_mean) / y_std)[:,cols_to_norm]\n",
        "    y[k]=v\n",
        "\n",
        "\n",
        "  y = {k: v.float() for k, v in y.items()}\n",
        "\n",
        "  train_loader = zero.data.IndexLoader(len(X['train'][0]), batch_size, device=device)\n",
        "  progress = zero.ProgressTracker(patience=100)\n",
        "  loss_fn = cross_entropy_mse_loss_with_nans\n",
        "\n",
        "def boxplot(vars,bad_value=None):\n",
        "  i=j=min(5,len(vars))\n",
        "  for _,var in enumerate(vars):\n",
        "      if isinstance(var,list):\n",
        "        y=pd.Series()\n",
        "        for name in var:\n",
        "          if name in dfo.columns:\n",
        "            y=y.append(dfo[name],ignore_index = True)\n",
        "      else:\n",
        "        y=dfo[var] if var in dfo.columns else []\n",
        "        name=var\n",
        "      if len(y)>0:\n",
        "        if i>=j:\n",
        "          figure, axes = plt.subplots(1,j,figsize=(16,8))\n",
        "          i=0\n",
        "        axs=axes.flat[i]\n",
        "        i+=1\n",
        "        if bad_value is not None and y.min()<=bad_value:\n",
        "          mask=y!=bad_value\n",
        "          name=f'{name}_{mask.sum()/len(mask):.0%}'\n",
        "          y=y[mask]\n",
        "        sns.boxplot(ax=axs, y=y, showmeans=True,\n",
        "                          meanprops={\"marker\": \"+\",\n",
        "                        \"markeredgecolor\": \"black\",\n",
        "                        \"markersize\": \"10\"})\n",
        "        axs.set_title(name)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def set_state(state: Dict[str, Any]) -> None:\n",
        "    \"\"\"Set global random states in `random`, `numpy` and `torch`.\n",
        "\n",
        "    Args:\n",
        "        state: global RNG states. Must be produced by `get_state`. The size of the list\n",
        "            :code:`state['torch.cuda']` must be equal to the number of available cuda\n",
        "            devices.\n",
        "\n",
        "    See also:\n",
        "        `get_state`\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: if :code:`torch.cuda.device_count() != len(state['torch.cuda'])`\n",
        "    \"\"\"\n",
        "    random.setstate(state['random'])\n",
        "    np.random.set_state(state['numpy.random'])\n",
        "    torch.random.set_rng_state(state['torch.random'].cpu())\n",
        "    assert torch.cuda.device_count() == len(state['torch.cuda'])\n",
        "    torch.cuda.set_rng_state_all([v.cpu() for v in state['torch.cuda']])  # type: ignore\n",
        "\n",
        "zero.random.set_state=set_state\n",
        "\n",
        "#====================================================train=================================\n",
        "# next_dep = 0\n",
        "# next_dep=1\n",
        "# next_dep=2\n",
        "# next_dep=3\n",
        "resume = True  # False#\n",
        "# tables = ['volcva.csv']\n",
        "# tables = ['volcvN.csv','volcvT.csv','volcvA.csv','volcvG.csv']\n",
        "dfo, cont_names=get_cont_names()\n",
        "\n",
        "# dfo.sort_values(by=['date'],inplace=True)\n",
        "enc = OrdinalEncoder()\n",
        "dfo[cat_names] = enc.fit_transform(dfo[cat_names])\n",
        "X_all = dfo.loc[:, cat_names + vars_c + cont_names].to_numpy().astype('float32')\n",
        "\n",
        "print(dfo.shape, X_all.shape,len(dep_vars[0]))\n",
        "zero_perc=(1-len(dfo[dfo['close']>0])/len(dfo)+len(dfo[dfo['close']<0])/len(dfo))/2\n",
        "print(zero_perc,dfo['close'].quantile([0]+[i*(zero_perc-0.005)/9.5+0.005 for i in range(10)]+[0.995-(0.995-zero_perc)/10.5*(21-i) for i in range(11,22)]+[1]))\n",
        "# boxplot(vars_h[1:],bad_value)\n",
        "# boxplot([[f'{var}_{i+1}' for i in range(duration)] for var in vars_h[1:]],0)\n",
        "\n",
        "#=====================================================run====================================\n",
        "next_dep=0\n",
        "# resume=False#s\n",
        "# resume=True#False#\n",
        "# ignore_load_error=True\n",
        "# ignore_load_zero=True\n",
        "\n",
        "n_epochs = 2000\n",
        "n_trials = 80\n",
        "start_epoch = 1\n",
        "sub_epochs=15\n",
        "\n",
        "for dep_sec in range(next_dep, len(dep_vars)):\n",
        "    n_no_improve = 0\n",
        "    setup_data()\n",
        "    print(X['train'][0].shape, X['train'][1].shape, y['train'].shape)\n",
        "    validate()\n",
        "    resume=True\n",
        "    # report_frequency = len(X['train']) // batch_size // 5\n",
        "    for epoc in range(start_epoch, n_epochs , sub_epochs):\n",
        "      for epoch in range(epoc,epoc+sub_epochs):\n",
        "        for iteration, batch_idx in enumerate(train_loader):\n",
        "            my_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            x_batch = (X['train'][0][batch_idx] if len(cat_names)>0 else None,\n",
        "                       X['train'][1][batch_idx],\n",
        "                       X['train'][2][batch_idx])\n",
        "            y_batch = y['train'][batch_idx]\n",
        "            loss = loss_fn(\n",
        "                apply_model(my_model,\n",
        "                            x_cat=x_batch[0] if len(cat_names)>0 else None,\n",
        "                            x_num=x_batch[1], x2=x_batch[2]).squeeze(1),\n",
        "                y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # if iteration % report_frequency == 0:\n",
        "            #     print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
        "\n",
        "        val_score = evaluate()[0]\n",
        "        # test_score = evaluate(my_model,'test')[0]\n",
        "        print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f}', end=\" \")\n",
        "        progress.update(-val_score)\n",
        "        if progress.success:\n",
        "            print(' <<< BEST VALIDATION EPOCH')\n",
        "            save_model(True)\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            # save_model(False)\n",
        "            n_no_improve += 1\n",
        "            print(f' no improve {n_no_improve}')\n",
        "        if progress.fail or val_score < .01 or n_no_improve > n_trials:\n",
        "            break\n",
        "      if progress.fail or val_score < .01 or n_no_improve > n_trials:\n",
        "        break\n",
        "      if n_no_improve>sub_epochs:\n",
        "        setup_data(True)\n",
        "    load_model(load_good=True)\n",
        "    with open(mydrive + jobname, 'wb') as filehandler:\n",
        "        dump((my_model, y_std, y_mean, enc), filehandler)\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3m_WUXL5ynz"
      },
      "source": [
        "# check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-EYvCnR52Dn"
      },
      "outputs": [],
      "source": [
        "      df=dfo[(dfo['date_6']>45225.6)&(dfo['date_6']<45225.7)&(dfo['date_5']>45224.6)&(dfo['date_5']<45224.7)&(dfo['Horizon']==1)&(dfo['spot']<-1.45)&(dfo['spot']>-1.46)]\n",
        "      dep_var=dep_vars[0]+dep_vars[1]\n",
        "      X, y = ({'test':\n",
        "                (  # dfo.loc[:,cat_names+vars_c+cont_names].to_numpy().astype('float32')},{}\n",
        "                    torch.tensor(df.loc[:, cat_names].to_numpy(), device=device).to(torch.int64),\n",
        "                    torch.tensor(df.loc[:, cont_names].to_numpy().astype('float32').reshape((df.shape[0], int(len(cont_names) / duration), duration)), device=device),\n",
        "                    torch.tensor(df.loc[:, vars_c].to_numpy().astype('float32'), device=device),\n",
        "                )\n",
        "                }, {'test': torch.tensor(df.loc[:,dep_var].to_numpy(), device=device).float()})\n",
        "      print('duration: ', duration,df.shape, X['test'][0].shape, X['test'][1].shape, X['test'][2].shape)\n",
        "      y['test'][:,-1]-=1\n",
        "\n",
        "      #for learner in models:\n",
        "      jobname = job_name()\n",
        "      my_model, y_std, y_mean, enc = models\n",
        "      y['test'][y['test']==bad_value]=float('nan')\n",
        "      cols_to_norm=[i for i in range(len(dep_var)) if not dep_var[i][:3] in ['dtm','pmc']]\n",
        "      y['test'][:,cols_to_norm]=((y['test']-y_mean) / y_std)[:,cols_to_norm].float()\n",
        "      score,target, prediction,prediction2 = evaluate(my_model,'test')\n",
        "      print(score,target, prediction,prediction2 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsLa3Ff5DRED"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=8)\n",
        "X['test'][1][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['test'][1].shape,X['test'][2].shape"
      ],
      "metadata": {
        "id": "3UYT9j3vE72r",
        "outputId": "e76632ce-95a1-46fb-a67d-b42f1762591d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 33, 6]), torch.Size([2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkhbd9_oGZoR"
      },
      "source": [
        "# end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUwM9_iOoIwF"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7XAUIkui5Am"
      },
      "outputs": [],
      "source": [
        "dfo[dfo['']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGqI7tkxsVl5"
      },
      "outputs": [],
      "source": [
        "print(f\"date_1:{X['test'][1][mini][0][0]} dtm:{target[mini][0]} diff_1:{X['test'][1][mini][1][0]} dtm_1:{X['test'][1][mini][6][0]}Horizon:{X['test'][2][mini][0]}\")\n",
        "dfo[(dfo['dtm']==int(target[mini][0]))&(dfo['date_1']>=int(X['test'][1][mini][0][0]*100-.5)/100.)&(dfo['date_1']<=int(X['test'][1][mini][0][0]*100+1)/100.)&(dfo['diff_1']==int(X['test'][1][mini][1][0]))&(dfo['dtm_1']==int(X['test'][1][mini][6][0]))&(dfo['Horizon']==int(X['test'][2][mini][0]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vow4wUCeW6ux"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_colwidth', None,'display.max_rows', None):\n",
        "  display(dfo[(dfo['dtm']==int(target[mini][0]))&(dfo['date_1']>=int(X['test'][1][mini][0][0]*100-.5)/100.)&(dfo['date_1']<=int(X['test'][1][mini][0][0]*100+1)/100.)&(dfo['diff_1']==int(X['test'][1][mini][1][0]))&(dfo['dtm_1']==int(X['test'][1][mini][6][0]))&(dfo['Horizon']==int(X['test'][2][mini][0]))].iloc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7XF0r4s9ayL"
      },
      "outputs": [],
      "source": [
        "sns.histplot( dfo[(dfo['Horizon']==0)]['close'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga5pgW6y-ps4"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_colwidth', None,'display.max_rows', None):\n",
        "  display(df.iloc[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}